lab 1
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder  # For encoding and scaling

from google.colab import files
uploaded = files.upload() 
import pandas as pd
data = pd.read_csv('customer.csv')  # or use the uploaded filename
print(data.head(15))
print(data.info())
# Step 4: Creating Independent and Dependent Variables
X = data.iloc[:, :-1].values  # Features (excluding target column)
y = data.iloc[:, -1].values   # Target variable
#Checking missing value
data.isnull().sum()
# Replacing missing values with the mean of the respective columns
data['Age'] = data['Age'].fillna(data['Age'].mean())  # Fill missing values in 'Age' with mean
data['Salary'] = data['Salary'].fillna(data['Salary'].mean())
print(data.head(10))
#One hot encoding
data = pd.get_dummies(data, columns=['Purchased'])
df_encoded=data.applymap(int)
print(df_encoded.head(10))
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder

# Step 1: Importing the dataset
data = pd.read_csv('customer.csv')

# Step 2: Displaying basic information about the data
print(data.head())
print(data.info())

# Step 3: Splitting the dataset into independent (X) and dependent (y) variables
X = data.drop(columns=['Purchased'])  # Independent variables
y = data['Purchased']  # Dependent variable (target)

# Step 4: Handling missing values
# Replace missing values in numerical columns with their mean
for column in X.select_dtypes(include=['float64', 'int64']).columns:
    X[column] = X[column].fillna(X[column].mean())

# Replace missing values in categorical columns with their mode
for column in X.select_dtypes(include=['object']).columns:
    X[column] = X[column].fillna(X[column].mode()[0])

# Step 5: Encoding categorical data
X = pd.get_dummies(X, drop_first=True)
y = pd.get_dummies(y, drop_first=True)

# Step 6: Splitting the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 8: Displaying the processed data
print("Processed Training Features (X_train):")
print(X_train)
print("Processed Test Features (X_test):")
print(X_test)
print("Target Training Data (y_train):")
print(y_train)
print("Target Test Data (y_test):")
print(y_test)

# Specify the categorical column
categorical_column = ['Purchased']

# Initialize OneHotEncoder (use sparse_output instead of sparse)
encoder = OneHotEncoder(sparse_output=False)

# Apply OneHotEncoder to the categorical column
encoded_data = encoder.fit_transform(data[['Purchased']])

# Convert the result back to a DataFrame for better readability
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_column))

# Concatenate the original dataset with the encoded columns and drop the original categorical columns
data_encoded_sklearn = pd.concat([data, encoded_df], axis=1).drop(categorical_column, axis=1)

# Display the dataset after one-hot encoding using sklearn
print("\nDataset after One-Hot Encoding (sklearn):")
print(data_encoded_sklearn)
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv('customer.csv')

# Display the first 15 rows of the dataset
print(data.head(15))

# 1. Bar Plot for Gender
plt.figure(figsize=(8, 5))
sns.countplot(data=data, x='Gender', palette='viridis')
plt.title('Bar Plot for Gender')
plt.show()

# 2. Bar Plot for Purchased
plt.figure(figsize=(8, 5))
sns.countplot(data=data, x='Purchased', palette='coolwarm')
plt.title('Bar Plot for Purchased')
plt.show()

# 3. Scatter Plot: Age vs Salary
plt.figure(figsize=(8, 5))
sns.scatterplot(data=data, x='Age', y='Salary', hue='Gender', palette='viridis')
plt.title('Scatter Plot of Age vs Salary')
plt.show()

# 4. Heatmap: Correlation between Age and Salary
numerical_data = data[['Age', 'Salary']]

# Compute correlation matrix
correlation_matrix = numerical_data.corr()

# Plot heatmap
plt.figure(figsize=(8, 5))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Heatmap of Age and Salary Correlation')
plt.show()

# 5. Enhanced Histogram: Age Distribution
plt.figure(figsize=(8, 5))
sns.histplot(data['Age'], bins=15, kde=True, color='dodgerblue', edgecolor='black', linewidth=1.2)
plt.title('Enhanced Histogram of Age Distribution')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

# 6. Pie Chart: Distribution of Purchased (with new colors)
purchase_counts = data['Purchased'].value_counts()
plt.figure(figsize=(8, 5))
purchase_counts.plot.pie(autopct='%1.1f%%', colors=['#ff9999', '#66b3ff'], startangle=90, cmap='coolwarm')
plt.title('Pie Chart of Purchased')
plt.ylabel('')  # Remove ylabel for better clarity
plt.show()
